## í™•ì¥ê°€ëŠ¥í•œ ë°ì´í„° ì¶”ì¶œ ì„œë¹„ìŠ¤ êµ¬ì¶• ê²½í—˜ì„ ê³µìœ  í•´ë³¼ê²Œìš”. 

## ğŸ˜… í˜„ì¬ì˜ ë¬¸ì œëŠ” ì•„ë˜ì™€ ê°™ì•„ìš”
> 1. ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ìš”ì²­ì„ í•˜ê²Œ ë˜ë©´, ì‚¬ìš©ìëŠ” ë°ì´í„°ë² ì´ìŠ¤ì˜ ì‘ë‹µì´ ëë‚ ë•Œê¹Œì§€ ë¸Œë¼ìš°ì €ì—ì„œ ë¡œë”©ë°”ë§Œ ë°”ë¼ë´ì•¼ í•´ìš”.
> 2. í…Œì´ë¸”ì´ ë§ê±°ë‚˜, ì–‘ì´ ë§ì€ ë°ì´í„°ë¥¼ ê°€ì ¸ ì™€ì•¼ í•˜ëŠ” ìƒí™©ì´ì—ìš”.
> 3. ë” í° ë¬¸ì œëŠ” ë™ê¸° ì ì¸ ë°©ì‹ì˜ êµ¬ì¡°ë¼ì„œ ë‹¤ìˆ˜ì¸ì›ì˜ ìš”ì²­ê¹Œì§€ ë“¤ì–´ì˜¤ê²Œ ë˜ë©´ ë°±ì—”ë“œ ì„œë¹„ìŠ¤ë„ ë¶€í•˜ê°€ ê³„ì† ë˜ê²Œ ë˜ìš”.
----

## ğŸ¤” ê³„íš
ê·¸ë˜ì„œ ë¹„ë™ê¸° ë°©ì‹ì„ ê°€ì§„, ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ 3ê°€ì§€ì˜ ë°©ë²•ì„ ì ìš© í•´ ë³´ì•˜ìŠµë‹ˆë‹¤.
> * ì²«ì§¸ ë¹„ë™ê¸°ë¡œëœ ì‘ë‹µ í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬í˜„í–ˆì–´ìš”.
> * ë‘˜ì§¸ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë¶€í„° ë°›ì€ ë°ì´í„°ë¥¼ ì—‘ì…€ë¡œ ë§Œë“¤ì–´ì¤„ ì„œë¹„ìŠ¤ë¥¼ ë³„ë„ ìƒì„±í•˜ì—¬ ê¸°ì¡´ ì„œë²„ì˜ ë¡œë“œë¥¼ ë¶„ì‚° ì‹œì¼°ì–´ìš”
> * ë§ˆì§€ë§‰ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œì— ìœ ë¦¬í•œ SpringBatch ë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆì–´ìš”.

ì‹œìŠ¤í…œ íë¦„ë„
> ![](img_3.png)
> * API Application
    >   + ìœ ì €ê°€ ìš”ì²­í• ë•Œ API Application ì—ì„œ ì¤‘ë³µ ìš”ì²­ì„ ë°©ì§€í•˜ì—¬ ë¡œë“œë¥¼ ë‚®ì¶¤.
> * Kafka
    >   + ì—‘ì…€ ìƒì„± ì´ë²¤íŠ¸ë¥¼ ì „ë‹¬í•˜ëŠ” ë¶€í•˜ ë¶„ì‚° ë¸Œë¡œì»¤ë¥¼ ë„ì….
> * Batch
    >   + ì—‘ì…€, json ë“± ì›í•˜ëŠ” ì¶”ì¶œ íƒ€ì…ì„ ë§Œë“¤ì–´ ì¤Œ.
> * S3
    >   + S3 ì— ì—…ë¡œë“œëœ ì—‘ì…€ì€ ì–¸ì œë“ ì§€ ì¬ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥

<hr/>

## ğŸ˜® SpringBatch ?


SpringBatch ëŠ” ë‹¤ìŒê³¼ ê°™ì€ Job ì„ ê°–ìŠµë‹ˆë‹¤.
> 1) Job ì—ëŠ” ë‹¤ì–‘í•œ Step ì´ ì¡´ì¬í•˜ê²Œ ë©ë‹ˆë‹¤.
> 2) Job ì´ ì‹œì‘í•˜ê±°ë‚˜ ëë‚ ë•Œ listener ë¥¼ ì„¤ì •í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•´ìš”.
> 3) ê°œë°œìëŠ” Step ë§Œ ì ì ˆíˆ ë“±ë¡í•˜ë©´ ë˜ëŠ” ì¥ì ì´ ìˆì–´ìš”.

```java
@Bean  
public Job partitionJob() {  
  return jobBuilderFactory.get("partitionJob")  
      .incrementer(new UniqueRunIdIncrementer())  
      .start(totalCountTasklet)  
      .next(partitionMainStep)  
      .next(excelMergeTasklet)  
      .next(s3UploadTasklet)  
      .listener(excelJobListener)  
      .build();  
}
```

* SpringBatch ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì¶”ì¶œí• ëŠ” ë°©ì‹ì€ ë³‘ë ¬ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
* ë°©ì‹ì€ ì•„ë˜ 4ê°€ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.
> 1. Multi-threaded Step
> 2. Parallel Steps
> 3. Remote Chunking
> 4. Partitioning

<hr/>

ë°ì´í„° ì¶”ì¶œ ì„œë¹„ìŠ¤ëŠ” ì•„ë˜ì˜ ì´ìœ ë¡œ Partitioning ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
> * í•˜ë‚˜ì˜ ë°ì´í„° ì¶”ì¶œ ìš”ì²­ì—, ì—­ì‹œ í•˜ë‚˜ì˜ Job ì´ ì‹¤í–‰ë˜ê³ , ë‹¤ìˆ˜ì˜ Partitioning ì‘ì—…ì´ ì§„í–‰ë˜ì–´ ì—‘ì…€ì„ ìƒì„±í•˜ëŠ”ë° íš¨ìœ¨ì ì¸ ë°©ì‹ì´ì—ìš”.
> * ì—¬ëŸ¬ ì—‘ì…€ íŒŒì¼ì„ ë§Œë“¤ê³ , ìµœì •ì ìœ¼ë¡œ í•œê°œë¡œ ë³‘í•© ì‘ì—… ë°©ì‹ì„ ì±„íƒ í•˜ì˜€ì–´ìš”.
> * Partitioningì€ í•˜ë‚˜ì˜ Job ì—ì„œ ë‹¤ìˆ˜ì˜ Secondary ë¥¼ ìƒì„± í•˜ê²Œ ë˜ìš”.

![](img_4.png)

> * PartitionStep ì˜ ë™ì‘ ë°©ì‹
    >  + ë‚´ë¶€ì ìœ¼ë¡œ Stepì„ ë¶„í• í•˜ì—¬ ë°˜ë³µ ì‹¤í–‰í•˜ë„ë¡ ì‹¤í–‰ë˜ëŠ” êµ¬ì¡°ì—ìš”.

![](img_5.png)

<hr/>

* PartitionStep ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„± í•˜ì˜€ì–´ìš”.
    + PartitionStepBuilder ê°ì²´ë¥¼ í†µí•´ì„œ PartitionStep ì´ ìƒì„±ë˜ëŠ” ë°©ì‹ì´ì—ìš”.

```java
@Bean  
public Step partitionMainStep() {
  return stepBuilderFactory.get("partitionMainStep")  
      .partitioner("subStep", partitioner(null, null, null)) // partitioner ì‚¬ì´ì¦ˆ ë° ì˜µì…˜ ë¶€ì—¬
      .step(partitionSubStep())  // step ë¶„í•  repeat ëŒ€ìƒ 
      .taskExecutor(taskExecutor) // ë™ê¸° or ë¹„ë™ê¸°, task ì˜µì…˜ ì„¤ì •
      .build();  
}
```


ì•„ë˜ëŠ” PartitionStep ì„ ìƒì„±í• ë•Œ PartitionStepBuilder ì˜ build() ë¥¼ í˜¸ì¶œí•˜ì—¬ ê°ì²´ë¥¼ ìƒì„± í•˜ê²Œ ë©ë‹ˆë‹¤.
```java
public Step build() {  
 PartitionStep step = new PartitionStep();  
 step.setName(getName());  
 super.enhance(step);  
  
 if (partitionHandler != null) {  
  step.setPartitionHandler(partitionHandler);  
 }  
 else {  
  TaskExecutorPartitionHandler partitionHandler = new TaskExecutorPartitionHandler();  
  partitionHandler.setStep(this.step);  
  if (taskExecutor == null) {  
   taskExecutor = new SyncTaskExecutor();  
  }  
  partitionHandler.setGridSize(gridSize);  
  partitionHandler.setTaskExecutor(taskExecutor);  
  step.setPartitionHandler(partitionHandler);  
 }  
  
 if (splitter != null) {  
  step.setStepExecutionSplitter(splitter);  
 }  
 else {  
  
  boolean allowStartIfComplete = isAllowStartIfComplete();  
  String name = stepName;  
  if (this.step != null) {  
   try {  
    allowStartIfComplete = this.step.isAllowStartIfComplete();  
    name = this.step.getName();  
   }  
   catch (Exception e) {  
    if (logger.isInfoEnabled()) {  
     logger.info("Ignored exception from step asking for name and allowStartIfComplete flag. "  
       + "Using default from enclosing PartitionStep (" + name + "," + allowStartIfComplete + ").");  
    }  
   }  
  }  
  SimpleStepExecutionSplitter splitter = new SimpleStepExecutionSplitter();  
  splitter.setPartitioner(partitioner);  
  splitter.setJobRepository(getJobRepository());  
  splitter.setAllowStartIfComplete(allowStartIfComplete);  
  splitter.setStepName(name);  
  this.splitter = splitter;  
  step.setStepExecutionSplitter(splitter);  
  
 }  
  
 if (aggregator != null) {  
  step.setStepExecutionAggregator(aggregator);  
 }  
  
 try {  
  step.afterPropertiesSet();  
 }  
 catch (Exception e) {  
  throw new StepBuilderException(e);  
 }  
  
 return step;  
  
}
```

ì•„ë˜ PartitionStep Execute ë¥¼ ì‹¤í–‰í•˜ì—¬ ì§„í–‰í•˜ê²Œ ë˜êµ¬ìš”.
```java
protected void doExecute(StepExecution stepExecution) throws Exception {  
  
 if(hasReducer) {  
  reducer.beginPartitionedStep();  
 }  
  
 // Wait for task completion and then aggregate the results  
 Collection<StepExecution> stepExecutions = getPartitionHandler().handle(null, stepExecution);  
 stepExecution.upgradeStatus(BatchStatus.COMPLETED);  
 stepExecutionAggregator.aggregate(stepExecution, stepExecutions);  
  
 if (stepExecution.getStatus().isUnsuccessful()) {  
  if (hasReducer) {  
   reducer.rollbackPartitionedStep();  
   reducer.afterPartitionedStepCompletion(PartitionStatus.ROLLBACK);  
  }  
  throw new JobExecutionException("Partition handler returned an unsuccessful step");  
 }  
  
 if (hasReducer) {  
  reducer.beforePartitionedStepCompletion();  
  reducer.afterPartitionedStepCompletion(PartitionStatus.COMMIT);  
 }  
}
```  

<hr/>

## ğŸ¤  ë‹¤ìŒì€ Batch í˜¸ì¶œ ë°©ë²•ì„ ì„¤ëª… í•´ ë³¼ê²Œìš”.
#### 1. ì‹œìŠ¤í…œ ( TeamCity ) - ì„œë²„ ì›ê²© í˜¸ì¶œ
> TeamCity Trigger ë¥¼ ë“±ë¡ í•´ì¤ë‹ˆë‹¤.
>
> ì•„ë˜ëŠ” 0ë¶„ ë§ˆë‹¤ spring-batch.jar ì„ ì‹¤í–‰í•˜ëŠ” Build ì— ëŒ€í•œ ë‚´ìš©ì´êµ¬ìš”.

* Schedule Trigger 0ë¶„ ë§ˆë‹¤ Build í•˜ëŠ” ìŠ¤ì¼€ì¤„
<br>
![](img_1.png)
* ì›ê²© ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
<br>
![](img_2.png)
#### 2. ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš© ( crontab ) - ì„œë²„ ì§ì ‘ ë“±ë¡
> linux ì˜ crontab -l, e, r ë“± ëª…ë ¹ì–´ë¡œ ìŠ¤ì¼€ì¤„ ë“±ë¡
>
> ì•„ë˜ëŠ” 0ë¶„ ë§ˆë‹¤ spring-batch.jar ì„ ì‹¤í–‰í•˜ëŠ” ìŠ¤ì¼€ì¤„

![](img.png)
#### 3. Kafka Consume - ì´ë²¤íŠ¸ í˜¸ì¶œ
> kafkaì˜ ì´ë²¤íŠ¸ê°€ ë°œí–‰ ë˜ì—ˆì„ë•Œë§ˆë‹¤ consume í•©ë‹ˆë‹¤.
>
> ë°°ì¹˜ì˜ ì‹¤í–‰ì€ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì•„ë‹Œ ì´ë²¤íŠ¸ì˜í•´ íŠ¸ë¦¬ê±°ë©ë‹ˆë‹¤.

* @KafkaListener ë¥¼ ì‚¬ìš©í•˜ì—¬, Consume í•˜ë„ë¡ ì„¤ì •
```java
@KafkaListener(  
    topics = "${spring.kafka.topic}",  
    clientIdPrefix = "${spring.kafka.topic.client-id}"  
)  
public void batchConsumer() throws JobInstanceAlreadyCompleteException, JobExecutionAlreadyRunningException, JobParametersInvalidException, JobRestartException, JsonProcessingException {   
  
  createJobLauncher.run(partitionJob,  
        new JobParametersBuilder()  
            .toJobParameters()  
    );  
}
```

<hr/>

## ğŸ™‚ ë§ˆë¬´ë¦¬
ìŠ¤í”„ë§ ë°°ì¹˜ë¥¼ ìŠ¤ì¼€ì¥´ëŸ¬ ë°©ì‹ ë³´ë‹¤ ì´ë²¤íŠ¸ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ì„œ,

ì´ë²¤íŠ¸ ë°©ì‹ì€ ì–´ë–»ê²Œ ì‚¬ìš©ì„ í•´ì•¼ í•˜ëŠ”ì§€, ë˜ êµ¬ì¡°ëŠ” ì–´ë–»ê²Œ ì„¤ê³„ í•´ì•¼ í•˜ëŠ”ì§€ ë“±ì„ ì•Œê²Œ ë˜ëŠ” ê²½í—˜ì´ì˜€ìŠµë‹ˆë‹¤.

ë˜í•œ, ë ˆê±°ì‹œì˜ ê¸°ëŠ¥ì„ ë³´ë‹¤ ì•ˆì „í•˜ê²Œ ìš´ì˜í•˜ê¸° ìœ„í•œ ë°©ë²•ì— ëŒ€í•´ ê³ ë¯¼ í•  ìˆ˜ ìˆëŠ” ì‹œê°„ì´ê¸°ë„ í–ˆìŠµë‹ˆë‹¤.

ê·¸ëŸ¼ ì—¬ê¸°ê¹Œì§€ ì œ ê²½í—˜ì„ ê³µìœ í•˜ê³  ì´ë§Œ ë§ˆë¬´ë¦¬ í•´ë³´ê² ìŠµë‹ˆë‹¤.

ì½ì–´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.


ì°¸ê³ 
<br>
https://docs.spring.io/spring-batch/docs/current/reference/html/scalability.html#partitioning 
